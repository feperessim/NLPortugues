{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/alan-barzilay/NLPortugues/blob/master/imagens/logo_nlportugues.png?raw=true\"  style=\"height:65%\" align=\"right\">\n",
    "\n",
    "\n",
    "# Lista10 - BERT\n",
    "**Nome: Felipe de Lima Peressim** \n",
    "\n",
    "**Numero Usp: 11823558** \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "______________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O objetivo desta lista é fazer com que vocês se familiarizem com o BERT por meio da biblioteca HuggingFace. Novamente, as questões 1 2 e 3 podem ser copiadas de listas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    TFBertForSequenceClassification,\n",
    "    TFTrainer,\n",
    "    TFTrainingArguments,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os dados como um dataframe\n",
    "\n",
    "Para esta lista nós utilizaremos o dataset **B2W-Reviews01** que consiste em avaliações de mais de 130k compras online no site Americanas.com e [esta disponivel no github](https://github.com/b2wdigital/b2w-reviews01) sob a licensa CC BY-NC-SA 4.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>site_category_lv1</th>\n",
       "      <th>site_category_lv2</th>\n",
       "      <th>review_title</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer_birth_year</th>\n",
       "      <th>reviewer_gender</th>\n",
       "      <th>reviewer_state</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:11:28</td>\n",
       "      <td>d0fb1ca69422530334178f5c8624aa7a99da47907c44de...</td>\n",
       "      <td>132532965</td>\n",
       "      <td>Notebook Asus Vivobook Max X541NA-GO472T Intel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Informática</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Bom</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
       "      <td>1958</td>\n",
       "      <td>F</td>\n",
       "      <td>RJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:13:48</td>\n",
       "      <td>014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...</td>\n",
       "      <td>22562178</td>\n",
       "      <td>Copo Acrílico Com Canudo 500ml Rocie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Utilidades Domésticas</td>\n",
       "      <td>Copos, Taças e Canecas</td>\n",
       "      <td>Preço imbatível, ótima qualidade</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
       "      <td>1996</td>\n",
       "      <td>M</td>\n",
       "      <td>SC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:26:02</td>\n",
       "      <td>44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...</td>\n",
       "      <td>113022329</td>\n",
       "      <td>Panela de Pressão Elétrica Philips Walita Dail...</td>\n",
       "      <td>philips walita</td>\n",
       "      <td>Eletroportáteis</td>\n",
       "      <td>Panela Elétrica</td>\n",
       "      <td>ATENDE TODAS AS EXPECTATIVA.</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
       "      <td>1984</td>\n",
       "      <td>M</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:35:54</td>\n",
       "      <td>ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...</td>\n",
       "      <td>113851581</td>\n",
       "      <td>Betoneira Columbus - Roma Brinquedos</td>\n",
       "      <td>roma jensen</td>\n",
       "      <td>Brinquedos</td>\n",
       "      <td>Veículos de Brinquedo</td>\n",
       "      <td>presente mais que desejado</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
       "      <td>1985</td>\n",
       "      <td>F</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:00:28</td>\n",
       "      <td>7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...</td>\n",
       "      <td>131788803</td>\n",
       "      <td>Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...</td>\n",
       "      <td>lg</td>\n",
       "      <td>TV e Home Theater</td>\n",
       "      <td>TV</td>\n",
       "      <td>Sem duvidas, excelente</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
       "      <td>1994</td>\n",
       "      <td>M</td>\n",
       "      <td>MG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       submission_date                                        reviewer_id  \\\n",
       "0  2018-01-01 00:11:28  d0fb1ca69422530334178f5c8624aa7a99da47907c44de...   \n",
       "1  2018-01-01 00:13:48  014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...   \n",
       "2  2018-01-01 00:26:02  44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...   \n",
       "3  2018-01-01 00:35:54  ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...   \n",
       "4  2018-01-01 01:00:28  7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...   \n",
       "\n",
       "   product_id                                       product_name  \\\n",
       "0   132532965  Notebook Asus Vivobook Max X541NA-GO472T Intel...   \n",
       "1    22562178               Copo Acrílico Com Canudo 500ml Rocie   \n",
       "2   113022329  Panela de Pressão Elétrica Philips Walita Dail...   \n",
       "3   113851581               Betoneira Columbus - Roma Brinquedos   \n",
       "4   131788803  Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...   \n",
       "\n",
       "    product_brand      site_category_lv1       site_category_lv2  \\\n",
       "0             NaN            Informática                Notebook   \n",
       "1             NaN  Utilidades Domésticas  Copos, Taças e Canecas   \n",
       "2  philips walita        Eletroportáteis         Panela Elétrica   \n",
       "3     roma jensen             Brinquedos   Veículos de Brinquedo   \n",
       "4              lg      TV e Home Theater                      TV   \n",
       "\n",
       "                       review_title  overall_rating recommend_to_a_friend  \\\n",
       "0                               Bom               4                   Yes   \n",
       "1  Preço imbatível, ótima qualidade               4                   Yes   \n",
       "2      ATENDE TODAS AS EXPECTATIVA.               4                   Yes   \n",
       "3        presente mais que desejado               4                   Yes   \n",
       "4            Sem duvidas, excelente               5                   Yes   \n",
       "\n",
       "                                         review_text reviewer_birth_year  \\\n",
       "0  Estou contente com a compra entrega rápida o ú...                1958   \n",
       "1  Por apenas R$1994.20,eu consegui comprar esse ...                1996   \n",
       "2  SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...                1984   \n",
       "3  MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...                1985   \n",
       "4  A entrega foi no prazo, as americanas estão de...                1994   \n",
       "\n",
       "  reviewer_gender reviewer_state Unnamed: 14 Unnamed: 15 Unnamed: 16  \\\n",
       "0               F             RJ         NaN         NaN         NaN   \n",
       "1               M             SC         NaN         NaN         NaN   \n",
       "2               M             SP         NaN         NaN         NaN   \n",
       "3               F             SP         NaN         NaN         NaN   \n",
       "4               M             MG         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 17 Unnamed: 18  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus = pd.read_csv(\"https://raw.githubusercontent.com/abarbosa94/NLPortugues/master/Semana%2009/data/b2w-10k.csv\")\n",
    "b2wCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Estou contente com a compra entrega rápida o ú...\n",
       "1       Por apenas R$1994.20,eu consegui comprar esse ...\n",
       "2       SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...\n",
       "3       MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...\n",
       "4       A entrega foi no prazo, as americanas estão de...\n",
       "                              ...                        \n",
       "9994    Celular muito rápido, com processador e armaze...\n",
       "9995    achei o produto muito frágil, o material veio ...\n",
       "9996    Uma porcaria pois ñ recebi ñ recomendo pra nin...\n",
       "9997    Maquina excelente,super pratica. recomendo.ent...\n",
       "9998    Agradeço pelo compromisso, obrigado. ,...........\n",
       "Name: review_text, Length: 9999, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"review_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pré-processamento\n",
    "Seria util nos livrarmos das colunas que não são relevantes para o nosso problema e tambem verificar se não tem nada de esquisito nas colunas que vamos utilizar. \n",
    "Por exemplo, se fossemos utilizar a coluna \"reviewer_gender\" nós precisariamos nos livrar desses valores esquisitos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M                                                                         5033\n",
       "F                                                                         4624\n",
       "                                                                             1\n",
       "Ocorrência: Z-Devolução Em Andamento Ao Cd de São Paulo 22/12/17 16:12       1\n",
       "1970                                                                         1\n",
       "Name: reviewer_gender, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"reviewer_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Questão 1 </font>\n",
    "\n",
    "a) Selecione apenas as colunas relevantes: \"review_text\" e \"recommend_to_a_friend\". \n",
    "\n",
    "b) Converta a coluna \"recommend_to_a_friend\" de uma coluna de `str` para uma coluna de `int`:\n",
    "\n",
    "- \"Yes\"-> 1\n",
    "- \"No\" -> 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2wCorpus['recommend_to_a_friend'] = b2wCorpus['recommend_to_a_friend'].apply(lambda word : 1 if str(word).lower() == 'yes' else 0)\n",
    "x = b2wCorpus['review_text'].values.astype('str')\n",
    "y = b2wCorpus['recommend_to_a_friend'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando em teste e treino\n",
    "## <font color='blue'>Questão 2 </font>\n",
    "\n",
    "Agora com o dataset já pré-processado, separe o em 2 partes, um conjunto de teste e um conjunto de treino. Novamente você pode utilizar a função [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do Scikit-Learn como na lista passada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizando\n",
    "\n",
    "Para aplicar o processo de _Tokenize_ dos nossos dados, diferente das listas anteriores, utilizaremos a classe [BertTokenizer](https://huggingface.co/transformers/master/model_doc/bert.html#berttokenizer) da biblioteca [transformers](https://github.com/huggingface/transformers) do HuggingFace.\n",
    "\n",
    "Para isso, veja o exemplo abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:16.090327 139954203100992 filelock.py:274] Lock 139951822711272 acquired on /home/felipe/.cache/torch/transformers/953e203ca70d433ab232eb85ae0093b7fd73a61d7931d54a460a131b5e15b10e.d2f3b3fde3658e304f905ed624bcacd8555c946377121f9211932f66c9fe1202.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6769c6b80e4f28b13b1c8b0988de64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=209528.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:17.464372 139954203100992 filelock.py:318] Lock 139951822711272 released on /home/felipe/.cache/torch/transformers/953e203ca70d433ab232eb85ae0093b7fd73a61d7931d54a460a131b5e15b10e.d2f3b3fde3658e304f905ed624bcacd8555c946377121f9211932f66c9fe1202.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:18.161253 139954203100992 filelock.py:274] Lock 139951822735512 acquired on /home/felipe/.cache/torch/transformers/e763f2a607ad8e4a10a0a8ca9b7e289e8704d9bf24ee520772ee28547721c295.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d79f484d72b4dc48cff9ab287e9a089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:19.025109 139954203100992 filelock.py:318] Lock 139951822735512 released on /home/felipe/.cache/torch/transformers/e763f2a607ad8e4a10a0a8ca9b7e289e8704d9bf24ee520772ee28547721c295.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:19.799683 139954203100992 filelock.py:274] Lock 139951822711272 acquired on /home/felipe/.cache/torch/transformers/aa29d58ec2f0278e3ff71ce26a902511a549e75a7596ae790a751253f2950b3d.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2867569709b14faaa629b6b33b789fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:20.670067 139954203100992 filelock.py:318] Lock 139951822711272 released on /home/felipe/.cache/torch/transformers/aa29d58ec2f0278e3ff71ce26a902511a549e75a7596ae790a751253f2950b3d.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:21.540782 139954203100992 filelock.py:274] Lock 139951822735400 acquired on /home/felipe/.cache/torch/transformers/316240c7b41ed25c9fc43a68d281f3f84a6efdb7f40cf1e9bd739e859285991b.d3d276ada459b0aec3a25156bf4df869f8362968dd3a7052748ad41fcb496476.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1cb514cf7245e5a431b0662d11049e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=43.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1106 16:59:22.325802 139954203100992 filelock.py:318] Lock 139951822735400 released on /home/felipe/.cache/torch/transformers/316240c7b41ed25c9fc43a68d281f3f84a6efdb7f40cf1e9bd739e859285991b.d3d276ada459b0aec3a25156bf4df869f8362968dd3a7052748ad41fcb496476.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "REF_MODEL = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(REF_MODEL)\n",
    "text = pd.DataFrame([\"isso é um text\", \"o rato roeu a roupa\", \"do rei de Roma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN=5\n",
    "encoded_text = tokenizer(\n",
    "    text.values.tolist(),\n",
    "    text_pair=None,\n",
    "    is_split_into_words=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=SEQ_LEN,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "encoded_text_labels = np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[ 101, 1257,  253,  222,  102],\n",
       "       [ 101,  146,  646,  183,  102],\n",
       "       [ 101,  171, 1754,  125,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3, 5), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível ver, o resultado gera um dicionário com 3 chaves, representando diferentes tensores:\n",
    "\n",
    "    - input_ids (os arrays de entrada convertidos para inteiro)\n",
    "    - token_type_ids (Indicação se pertence a sentença A ou B [0 é sentença A e 1 é sentença B])\n",
    "    - attention_mask (indicando quais tokens foram mascarados. Como todos os tokens **não** foram mascarados, o valor aqui sempre é 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Questão 3 </font>\n",
    "\n",
    "Aplique o tokenizer nos dados de treino e teste, gerando duas variáveis **encoded_train** e **encoded_test**, considerando o max_length como o tamanho da sentença ideal. Plotamos um histograma do comprimento dos reviews para lhe auxiliar nessa decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(linha.split()) for linha in b2wCorpus[\"review_text\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"bert-base-multilingual-cased\"\n",
    "REF_MODEL = 'neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(REF_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_MAXLEN = 50\n",
    "\n",
    "encoded_train = tokenizer(\n",
    "    [[line] for line in x_train],\n",
    "    text_pair=None,\n",
    "    is_split_into_words=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=SEQUENCE_MAXLEN,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='np'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_valid = tokenizer(\n",
    "   [[line] for line in x_val],\n",
    "    text_pair=None,\n",
    "    is_split_into_words=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=SEQUENCE_MAXLEN,\n",
    "    pad_to_max_length=True,\n",
    "    return_tensors='np'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6999, 50)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o modelo\n",
    "\n",
    "Para montar o modelo, iremos utilizar a classe TFBertForSequenceClassification, do HuggingFace\n",
    "\n",
    "Aqui tem um exemplo de código para vocês seguirem!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertForSequenceClassification.from_pretrained(REF_MODEL, from_pt=True, num_labels=2)\n",
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name='input_token', dtype='int32')\n",
    "input_masks_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name='masked_token', dtype='int32')\n",
    "\n",
    "X = bert_model(input_ids, input_masks_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_for_sequence_classifica ((None, 2),)         108924674   input_token[0][0]                \n",
      "                                                                 masked_token[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 108,924,674\n",
      "Trainable params: 108,924,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=2)]\n",
    "model.compile(opt, \"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1274 - acc: 0.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 17:21:46.097144 139954203100992 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 2.1274 - acc: 0.6667\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5341 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 17:21:48.734575 139954203100992 callbacks.py:1689] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5341 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [encoded_text[\"input_ids\"], encoded_text[\"attention_mask\"]],\n",
    "    encoded_text_labels,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    callbacks=my_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e avaliando seu modelo\n",
    "\n",
    "###  <font color='blue'>Questão 4 </font>\n",
    "\n",
    "Defina e treine seu modelo.\n",
    "\n",
    "**Lembre-se de tambem adicionar os dados de validação do modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertForSequenceClassification.from_pretrained(REF_MODEL, from_pt=True, num_labels=2)\n",
    "input_ids = tf.keras.layers.Input(shape=(SEQUENCE_MAXLEN,), name='input_token', dtype='int32')\n",
    "input_masks_ids = tf.keras.layers.Input(shape=(SEQUENCE_MAXLEN,), name='masked_token', dtype='int32')\n",
    "\n",
    "X = bert_model(input_ids, input_masks_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=10)]\n",
    "model.compile(opt, \"binary_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/110 [..............................] - ETA: 16:59 - loss: 7.3940 - acc: 0.2812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-75c2398b3ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     validation_data = ([encoded_valid[\"input_ids\"],\n\u001b[1;32m      9\u001b[0m                        encoded_valid[\"attention_mask\"]],\n\u001b[0;32m---> 10\u001b[0;31m                        y_val)\n\u001b[0m\u001b[1;32m     11\u001b[0m )    \n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [encoded_train[\"input_ids\"],\n",
    "     encoded_train[\"attention_mask\"]],\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=1,\n",
    "    callbacks=my_callbacks,\n",
    "    validation_data = ([encoded_valid[\"input_ids\"],\n",
    "                       encoded_valid[\"attention_mask\"]],\n",
    "                       y_val)\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
